<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Robot Controller</title>
  <style>
    :root {
      --bg1: #0a1f2e;
      --bg2: #123b53;
      --card: rgba(255, 255, 255, 0.12);
      --text: #f5fbff;
      --ok: #3ddc97;
      --warn: #ffd166;
      --btn: #ffffff;
      --btn-text: #0f2e42;
    }

    * { box-sizing: border-box; }

    body {
      margin: 0;
      min-height: 100vh;
      font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      color: var(--text);
      background:
        radial-gradient(circle at 20% 20%, rgba(61, 220, 151, 0.25), transparent 35%),
        radial-gradient(circle at 80% 80%, rgba(255, 209, 102, 0.2), transparent 30%),
        linear-gradient(135deg, var(--bg1), var(--bg2));
    }

    .panel {
      width: min(95vw, 980px);
      margin: 22px auto;
      padding: 24px;
      border-radius: 16px;
      background: var(--card);
      backdrop-filter: blur(6px);
      border: 1px solid rgba(255, 255, 255, 0.18);
      box-shadow: 0 18px 40px rgba(0, 0, 0, 0.28);
    }

    h1 {
      margin: 0 0 16px;
      text-align: center;
      letter-spacing: 0.08em;
      font-weight: 700;
      font-size: 1.35rem;
    }

    .controls {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 12px;
      margin-top: 10px;
    }

    .forward {
      grid-column: 1 / -1;
    }

    button {
      border: none;
      border-radius: 12px;
      padding: 14px 12px;
      font-size: 1rem;
      font-weight: 700;
      letter-spacing: 0.04em;
      color: var(--btn-text);
      background: var(--btn);
      cursor: pointer;
      transition: transform 120ms ease, box-shadow 120ms ease;
      box-shadow: 0 6px 16px rgba(0, 0, 0, 0.2);
    }

    button:hover { transform: translateY(-1px); }
    button:active { transform: translateY(1px) scale(0.99); }

    .status {
      margin-top: 16px;
      font-size: 0.95rem;
      text-align: center;
      min-height: 1.2em;
      color: var(--warn);
    }

    .status.ok { color: var(--ok); }

    .camera-wrap {
      position: relative;
      margin-top: 16px;
      border-radius: 12px;
      overflow: hidden;
      border: 1px solid rgba(255, 255, 255, 0.2);
      background: rgba(0, 0, 0, 0.2);
      aspect-ratio: 16 / 9;
    }

    #camera {
      width: 100%;
      height: 100%;
      display: block;
      object-fit: cover;
    }

    #overlay {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }

    .tracking-dock {
      position: fixed;
      right: 12px;
      bottom: 12px;
      width: min(34vw, 190px);
      aspect-ratio: 16 / 9;
      border-radius: 12px;
      overflow: hidden;
      border: 1px solid rgba(255, 255, 255, 0.35);
      background: rgba(0, 0, 0, 0.3);
      box-shadow: 0 10px 24px rgba(0, 0, 0, 0.35);
      z-index: 40;
      pointer-events: none;
    }

    #cameraMini {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      display: block;
    }

    #overlayMini {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }

    .auto-status {
      margin-top: 10px;
      text-align: center;
      font-size: 0.9rem;
      color: #dff2ff;
      min-height: 1.2em;
    }

    .ai-status {
      margin-top: 8px;
      text-align: center;
      font-size: 0.9rem;
      color: #c9ffe4;
      min-height: 1.2em;
    }

    .voice-btn {
      margin-top: 8px;
      width: 100%;
      display: none;
    }

    .rotate-hint {
      margin-top: 8px;
      font-size: 0.85rem;
      text-align: center;
      opacity: 0.85;
      display: none;
    }

    .mode-btn {
      margin-top: 10px;
      width: 100%;
    }

    .face-screen {
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-direction: column;
      width: 100vw;
      min-height: 100vh;
      margin-left: calc(50% - 50vw);
      margin-top: 18px;
      background:
        radial-gradient(circle at 20% 20%, rgba(61, 220, 151, 0.2), transparent 40%),
        radial-gradient(circle at 80% 80%, rgba(255, 209, 102, 0.18), transparent 40%),
        linear-gradient(160deg, #081a28, #0f2f45);
      padding: 20px;
    }

    .face-back {
      position: sticky;
      top: 12px;
      left: 12px;
      padding: 8px 10px;
      font-size: 0.8rem;
      border-radius: 10px;
      width: auto;
      align-self: flex-start;
    }

    .face-wrap {
      width: min(90vw, 480px);
      aspect-ratio: 1 / 1;
      border-radius: 34px;
      background: rgba(255, 255, 255, 0.1);
      border: 1px solid rgba(255, 255, 255, 0.2);
      box-shadow: 0 20px 50px rgba(0, 0, 0, 0.35);
      display: grid;
      place-items: center;
      animation: bob 2.2s ease-in-out infinite;
    }

    .face {
      width: 82%;
      height: 82%;
      border-radius: 32px;
      background: linear-gradient(160deg, #23789a, #1b4d6b);
      border: 1px solid rgba(255, 255, 255, 0.18);
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-direction: column;
      gap: 18px;
      overflow: hidden;
      transition: transform 160ms ease, box-shadow 160ms ease;
    }

    .face::before {
      content: "";
      position: absolute;
      width: 130%;
      height: 60%;
      top: -18%;
      left: -15%;
      background: radial-gradient(circle, rgba(255, 255, 255, 0.26), transparent 60%);
      pointer-events: none;
    }

    .eyes {
      width: 80%;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .eye {
      width: 36%;
      aspect-ratio: 1 / 1;
      border-radius: 48% 48% 44% 44%;
      background: linear-gradient(180deg, #ffffff, #e7f4ff);
      display: grid;
      place-items: center;
      overflow: hidden;
      animation: blink 5.2s infinite;
      position: relative;
      box-shadow: inset 0 -4px 0 rgba(12, 32, 45, 0.1);
    }

    .eye::after {
      content: "";
      position: absolute;
      width: 28%;
      height: 28%;
      border-radius: 50%;
      background: rgba(255, 255, 255, 0.85);
      top: 16%;
      left: 18%;
    }

    .eye::before {
      content: "";
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 24%;
      background: rgba(26, 78, 107, 0.22);
      border-bottom-left-radius: 45%;
      border-bottom-right-radius: 45%;
    }

    .pupil {
      width: 38%;
      aspect-ratio: 1 / 1;
      border-radius: 50%;
      background: radial-gradient(circle at 35% 35%, #2a4f67, #0b1f2d 70%);
      transform: translate(var(--px, 0), var(--py, 0));
      transition: transform 120ms ease;
    }

    .mouth {
      width: 38%;
      height: 14px;
      border-radius: 20px;
      background: #f8fdff;
      transform: scaleY(0.55);
      transition: transform 120ms ease, width 120ms ease, border-radius 120ms ease;
    }

    .face-label {
      margin-top: 12px;
      font-size: 0.9rem;
      opacity: 0.9;
      text-align: center;
    }

    .face-sub {
      margin-top: 6px;
      font-size: 0.78rem;
      opacity: 0.85;
      text-align: center;
      letter-spacing: 0.03em;
    }

    .face-face.listening .mouth {
      width: 34%;
      height: 20px;
      border-radius: 0 0 26px 26px;
      transform: scaleY(1);
    }

    .face-face.speaking .mouth {
      width: 36%;
      height: 28px;
      border-radius: 12px;
      transform: scaleY(1);
      animation: talk 200ms ease-in-out infinite alternate;
    }

    .face-face.thinking .mouth {
      width: 30%;
      height: 12px;
      border-radius: 0 0 22px 22px;
      transform: scaleY(0.85);
    }

    .face-face.error .mouth {
      width: 30%;
      transform: rotate(180deg) translateY(-4px);
    }

    .face-face.listening {
      box-shadow: 0 0 0 2px rgba(120, 255, 223, 0.45), 0 0 26px rgba(120, 255, 223, 0.25);
    }

    .face-face.speaking {
      box-shadow: 0 0 0 2px rgba(255, 246, 163, 0.42), 0 0 30px rgba(255, 246, 163, 0.24);
      transform: translateY(-2px);
    }

    .face-face.searching {
      box-shadow: 0 0 0 2px rgba(142, 196, 255, 0.42), 0 0 28px rgba(142, 196, 255, 0.22);
    }

    .face-face.error {
      box-shadow: 0 0 0 2px rgba(255, 142, 142, 0.5), 0 0 30px rgba(255, 142, 142, 0.22);
    }

    .face-face.searching .mouth {
      width: 24%;
      height: 10px;
      border-radius: 8px;
      transform: scaleY(0.8);
    }

    .face-face.searching .pupil {
      animation: searchLook 1.8s ease-in-out infinite;
    }

    .face-face.idle .mouth {
      width: 36%;
      height: 20px;
      border-radius: 0 0 26px 26px;
      transform: scaleY(1);
    }

    .face-face.thinking .eye {
      transform: scaleX(0.98) translateY(1px);
    }

    .face-face.left { --px: -7px; }
    .face-face.right { --px: 7px; }
    .face-face.forward { --px: 0px; }
    .face-face.stop { --px: 0px; --py: -3px; }

    @keyframes blink {
      0%, 43%, 47%, 100% { transform: scaleY(1); }
      45% { transform: scaleY(0.18); }
    }

    @keyframes talk {
      from { transform: scaleY(0.7) scaleX(0.92); }
      to { transform: scaleY(1.28) scaleX(1.08); }
    }

    @keyframes searchLook {
      0%, 100% { transform: translate(-8px, -2px); }
      25% { transform: translate(8px, -2px); }
      50% { transform: translate(6px, 4px); }
      75% { transform: translate(-7px, 3px); }
    }

    @keyframes bob {
      0%, 100% { transform: translateY(0); }
      50% { transform: translateY(-5px); }
    }

    @media (max-width: 900px) and (orientation: landscape) {
      .panel {
        width: 98vw;
        padding: 14px;
      }

      .controls {
        grid-template-columns: repeat(4, 1fr);
      }

      .forward {
        grid-column: auto;
      }

      h1 {
        font-size: 1.1rem;
        margin-bottom: 10px;
      }
    }

    @media (max-width: 900px) and (orientation: portrait) {
      .rotate-hint {
        display: block;
      }
    }
  </style>
</head>
<body>
  <main class="panel">
    <h1>Robot Drive Control</h1>
    <div class="controls">
      <button class="forward" data-command="FORWARD">FORWARD</button>
      <button data-command="LEFT">LEFT</button>
      <button data-command="RIGHT">RIGHT</button>
      <button data-command="STOP">STOP</button>
    </div>
    <div class="camera-wrap">
      <video id="camera" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
    </div>
    <p class="rotate-hint">Tip: rotate phone sideways for best tracking.</p>
    <p id="autoStatus" class="auto-status">Auto tracking: starting...</p>
    <p id="aiStatus" class="ai-status">AI voice: waiting for person...</p>
    <button id="voiceBtn" class="voice-btn" type="button">Tap to Enable Voice Listening</button>
    <button id="faceModeBtn" class="mode-btn" type="button">Face Mode</button>
    <p id="status" class="status">Ready</p>
  </main>

  <aside class="tracking-dock" aria-label="Tracking Preview">
    <video id="cameraMini" autoplay playsinline muted></video>
    <canvas id="overlayMini"></canvas>
  </aside>

  <section id="faceScreen" class="face-screen">
    <button id="faceBackBtn" class="face-back" type="button">Back</button>
    <div class="face-wrap">
      <div id="faceFace" class="face face-face forward idle">
        <div class="eyes">
          <div class="eye"><div class="pupil"></div></div>
          <div class="eye"><div class="pupil"></div></div>
        </div>
        <div class="mouth"></div>
      </div>
    </div>
    <p id="faceLabel" class="face-label">Face Mode: idle</p>
    <p id="faceSubLabel" class="face-sub">System online</p>
  </section>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

  <script>
    const endpoint = "https://192.168.86.22:8443/robot";
    const smartThingsEndpoint = "https://192.168.86.22:8443/smartthings";
    const weatherEndpoint = "https://192.168.86.22:8443/weather";
    const DEFAULT_WEATHER_LOCATION = "Mill Creek, Washington";
    const statusEl = document.getElementById("status");
    const autoStatusEl = document.getElementById("autoStatus");
    const aiStatusEl = document.getElementById("aiStatus");
    const voiceBtnEl = document.getElementById("voiceBtn");
    const faceModeBtnEl = document.getElementById("faceModeBtn");
    const faceBackBtnEl = document.getElementById("faceBackBtn");
    const faceFaceEl = document.getElementById("faceFace");
    const faceLabelEl = document.getElementById("faceLabel");
    const faceSubLabelEl = document.getElementById("faceSubLabel");
    const cameraEl = document.getElementById("camera");
    const cameraMiniEl = document.getElementById("cameraMini");
    const overlayEl = document.getElementById("overlay");
    const overlayCtx = overlayEl.getContext("2d");
    const overlayMiniEl = document.getElementById("overlayMini");
    const overlayMiniCtx = overlayMiniEl.getContext("2d");
    let lastCommand = "";
    let lastCommandAt = 0;
    let stableCandidateCommand = "";
    let stableCandidateCount = 0;
    const COMMAND_INTERVAL_MS = 140;
    const COMMAND_CHANGE_INTERVAL_MS = 220;
    const LEFT_THRESHOLD = 0.3;
    const RIGHT_THRESHOLD = 0.7;
    const STEER_ENTER_LEFT = 0.26;
    const STEER_ENTER_RIGHT = 0.74;
    const CENTER_SMOOTHING = 0.18;
    const KEYPOINT_THRESHOLD = 0.3;
    const NO_PERSON_RESET_MS = 2500;
    const LOST_CONFIRM_MS = 220;
    const PERSON_REACQUIRE_HOLD_MS = 420;
    const TURN_FLIP_GUARD_MS = 360;
    const GROQ_API_KEY = "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";
    const GROQ_MODEL = "llama-3.1-8b-instant";
    const GROQ_MIN_TURN_GAP_MS = 4000;
    const GROQ_COOLDOWN_MS = 30000;
    const adjacentPairs = poseDetection.util.getAdjacentPairs(
      poseDetection.SupportedModels.MoveNet
    );
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    let personVisible = false;
    let lastPersonAt = 0;
    let personLostSince = 0;
    let reacquireUntil = 0;
    let greetedForCurrentPresence = false;
    let recognition = null;
    let recognitionActive = false;
    let assistantBusy = false;
    let assistantSpeaking = false;
    let commandInFlight = false;
    let queuedCommand = null;
    let smoothedCenterX = null;
    let lastSteerCommand = "FORWARD";
    let lastTurnSetAt = 0;
    let voiceEnabled = true;
    let lastUserText = "";
    let lastUserTextAt = 0;
    let lastGroqCallAt = 0;
    let groqCooldownUntil = 0;
    let robotMotion = "forward";
    let aiMood = "idle";
    let aiMoodTimer = null;
    let searchSpinDirection = "RIGHT";
    let lastSeenXNormalized = 0.5;
    let audioContext = null;
    let audioEnabled = false;
    let conversation = [
      {
        role: "system",
        content: "You are a warm, friendly robot guide (but dont talk too much or repeat things randomly). Keep replies conversational, short, human-like, and never exceed 3 sentences of output. If user asks to control lights, append exactly one machine tag at the end: <SMARTTHINGS action=\"on|off\" target=\"name or all\" brightness=\"1-100 optional\" color=\"red|blue|green|yellow|purple|pink|white|warm|cool optional\"/>. If user asks about weather, append exactly one machine tag at the end: <WEATHER location=\"city or place\" type=\"current|forecast|air\" units=\"metric|imperial\"/>."
      }
    ];

    async function sendCommand(command) {
      statusEl.textContent = `Sending ${command}...`;
      statusEl.classList.remove("ok");

      try {
        const response = await fetch(endpoint, {
          method: "POST",
          headers: { "Content-Type": "text/plain" },
          body: command
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        statusEl.textContent = `${command} sent`;
        statusEl.classList.add("ok");
        if (["LEFT", "RIGHT", "FORWARD", "STOP"].includes(command)) {
          robotMotion = command.toLowerCase();
          updateFaceState();
        }
      } catch (error) {
        statusEl.textContent = `Failed: ${error.message}`;
        statusEl.classList.remove("ok");
      }
    }

    function setAIMood(nextMood, holdMs = 0) {
      aiMood = nextMood;
      updateFaceState();
      if (aiMoodTimer) {
        clearTimeout(aiMoodTimer);
        aiMoodTimer = null;
      }
      if (holdMs > 0) {
        aiMoodTimer = setTimeout(() => {
          if (!assistantSpeaking && !assistantBusy && !recognitionActive) {
            aiMood = "idle";
            updateFaceState();
          }
        }, holdMs);
      }
    }

    function updateFaceState() {
      if (!faceFaceEl) return;
      const motionClass = ["left", "right", "forward", "stop"].includes(robotMotion) ? robotMotion : "forward";
      const moodClass = ["idle", "listening", "speaking", "thinking", "error", "searching"].includes(aiMood) ? aiMood : "idle";
      faceFaceEl.className = `face face-face ${motionClass} ${moodClass}`;
      faceLabelEl.textContent = `Face Mode: ${moodClass} | motion: ${motionClass}`;
      if (faceSubLabelEl) {
        if (moodClass === "searching") faceSubLabelEl.textContent = "Scanning for you";
        else if (moodClass === "listening") faceSubLabelEl.textContent = "Listening...";
        else if (moodClass === "thinking") faceSubLabelEl.textContent = "Thinking...";
        else if (moodClass === "speaking") faceSubLabelEl.textContent = "Speaking";
        else if (moodClass === "error") faceSubLabelEl.textContent = "Recovering";
        else faceSubLabelEl.textContent = "Ready";
      }
    }

    function enterFaceMode() {
      const faceScreen = document.getElementById("faceScreen");
      faceScreen.scrollIntoView({ behavior: "smooth", block: "start" });
      updateFaceState();
    }

    function exitFaceMode() {
      window.scrollTo({ top: 0, behavior: "smooth" });
    }

    function ensureAudioContext() {
      if (audioContext) return;
      const Ctx = window.AudioContext || window.webkitAudioContext;
      if (!Ctx) return;
      audioContext = new Ctx();
    }

    async function unlockAudio() {
      try {
        ensureAudioContext();
        if (!audioContext) return;
        if (audioContext.state === "suspended") {
          await audioContext.resume();
        }
        audioEnabled = true;
      } catch (_) {
        audioEnabled = false;
      }
    }

    function playEarcon(type) {
      if (!audioEnabled || !audioContext) return;
      const osc = audioContext.createOscillator();
      const gain = audioContext.createGain();
      osc.connect(gain);
      gain.connect(audioContext.destination);

      const now = audioContext.currentTime;
      let startFreq = 440;
      let endFreq = 660;
      let dur = 0.12;
      if (type === "listen") { startFreq = 520; endFreq = 700; dur = 0.09; }
      if (type === "thinking") { startFreq = 320; endFreq = 480; dur = 0.11; }
      if (type === "found") { startFreq = 440; endFreq = 760; dur = 0.14; }
      if (type === "error") { startFreq = 340; endFreq = 240; dur = 0.14; }

      osc.type = "sine";
      osc.frequency.setValueAtTime(startFreq, now);
      osc.frequency.linearRampToValueAtTime(endFreq, now + dur);
      gain.gain.setValueAtTime(0.0001, now);
      gain.gain.linearRampToValueAtTime(0.05, now + 0.02);
      gain.gain.exponentialRampToValueAtTime(0.0001, now + dur);
      osc.start(now);
      osc.stop(now + dur + 0.01);
    }

    function getSearchCommand() {
      return searchSpinDirection === "LEFT" ? "LEFT" : "RIGHT";
    }

    function updateSearchDirectionFromLastSeen(centerX, frameWidth) {
      if (!frameWidth || centerX == null) return;
      lastSeenXNormalized = centerX / frameWidth;
      searchSpinDirection = lastSeenXNormalized < 0.5 ? "LEFT" : "RIGHT";
    }

    async function dispatchCommand(command) {
      commandInFlight = true;
      try {
        await sendCommand(command);
      } finally {
        commandInFlight = false;
        if (queuedCommand && queuedCommand !== command) {
          const next = queuedCommand;
          queuedCommand = null;
          dispatchCommand(next);
        }
      }
    }

    function sendCommandIfNeeded(command) {
      const now = Date.now();
      if (command !== stableCandidateCommand) {
        stableCandidateCommand = command;
        stableCandidateCount = 1;
        return;
      }

      stableCandidateCount++;
      if (command !== lastCommand && stableCandidateCount < 2) return;

      const minGap = command === lastCommand ? COMMAND_INTERVAL_MS : COMMAND_CHANGE_INTERVAL_MS;
      if (now - lastCommandAt < minGap) return;

      lastCommand = command;
      lastCommandAt = now;
      if (commandInFlight) {
        queuedCommand = command;
        return;
      }
      dispatchCommand(command);
    }

    function getHumanCenterX(pose) {
      const findPoint = (name) => pose.keypoints.find((k) => k.name === name && (k.score ?? 0) > KEYPOINT_THRESHOLD);
      const ls = findPoint("left_shoulder");
      const rs = findPoint("right_shoulder");
      const lh = findPoint("left_hip");
      const rh = findPoint("right_hip");
      const nose = findPoint("nose");

      let weightedSum = 0;
      let totalWeight = 0;
      if (ls && rs) {
        weightedSum += ((ls.x + rs.x) / 2) * 2.4;
        totalWeight += 2.4;
      }
      if (lh && rh) {
        weightedSum += ((lh.x + rh.x) / 2) * 2.0;
        totalWeight += 2.0;
      }
      if (nose) {
        weightedSum += nose.x * 0.6;
        totalWeight += 0.6;
      }

      if (totalWeight === 0) return null;
      return weightedSum / totalWeight;
    }

    function getHumanCenterY(pose) {
      const required = [
        "nose",
        "left_shoulder",
        "right_shoulder",
        "left_hip",
        "right_hip",
        "left_knee",
        "right_knee",
        "left_ankle",
        "right_ankle"
      ];
      const points = pose.keypoints.filter((k) => required.includes(k.name) && (k.score ?? 0) > KEYPOINT_THRESHOLD);
      if (!points.length) return null;
      return points.reduce((sum, p) => sum + p.y, 0) / points.length;
    }

    function syncOverlaySize() {
      const w = cameraEl.videoWidth;
      const h = cameraEl.videoHeight;
      if (!w || !h) return;
      if (overlayEl.width !== w || overlayEl.height !== h) {
        overlayEl.width = w;
        overlayEl.height = h;
      }
      const miniW = cameraMiniEl.clientWidth;
      const miniH = cameraMiniEl.clientHeight;
      if (miniW && miniH && (overlayMiniEl.width !== miniW || overlayMiniEl.height !== miniH)) {
        overlayMiniEl.width = miniW;
        overlayMiniEl.height = miniH;
      }
    }

    function drawSkeleton(pose) {
      syncOverlaySize();
      overlayCtx.clearRect(0, 0, overlayEl.width, overlayEl.height);
      overlayMiniCtx.clearRect(0, 0, overlayMiniEl.width, overlayMiniEl.height);
      if (!pose) return;

      overlayCtx.lineWidth = 3;
      overlayCtx.strokeStyle = "#3ddc97";
      overlayCtx.fillStyle = "#ffd166";
      overlayMiniCtx.lineWidth = 2;
      overlayMiniCtx.strokeStyle = "#3ddc97";
      overlayMiniCtx.fillStyle = "#ffd166";

      const sx = overlayMiniEl.width / (cameraEl.videoWidth || 1);
      const sy = overlayMiniEl.height / (cameraEl.videoHeight || 1);

      for (const [i, j] of adjacentPairs) {
        const kp1 = pose.keypoints[i];
        const kp2 = pose.keypoints[j];
        if (!kp1 || !kp2) continue;
        if ((kp1.score ?? 0) < KEYPOINT_THRESHOLD || (kp2.score ?? 0) < KEYPOINT_THRESHOLD) continue;

        overlayCtx.beginPath();
        overlayCtx.moveTo(kp1.x, kp1.y);
        overlayCtx.lineTo(kp2.x, kp2.y);
        overlayCtx.stroke();

        overlayMiniCtx.beginPath();
        overlayMiniCtx.moveTo(kp1.x * sx, kp1.y * sy);
        overlayMiniCtx.lineTo(kp2.x * sx, kp2.y * sy);
        overlayMiniCtx.stroke();
      }

      for (const kp of pose.keypoints) {
        if ((kp.score ?? 0) < KEYPOINT_THRESHOLD) continue;
        overlayCtx.beginPath();
        overlayCtx.arc(kp.x, kp.y, 4, 0, Math.PI * 2);
        overlayCtx.fill();

        overlayMiniCtx.beginPath();
        overlayMiniCtx.arc(kp.x * sx, kp.y * sy, 2.4, 0, Math.PI * 2);
        overlayMiniCtx.fill();
      }
    }

    function speak(text) {
      return new Promise((resolve) => {
        window.speechSynthesis.cancel();
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = 1.02;
        utterance.pitch = 1.05;
        utterance.onstart = () => {
          assistantSpeaking = true;
          setAIMood("speaking");
          playEarcon("thinking");
        };
        utterance.onend = () => {
          assistantSpeaking = false;
          setAIMood("idle");
          maybeStartListening();
          resolve();
        };
        utterance.onerror = () => {
          assistantSpeaking = false;
          setAIMood("error", 900);
          maybeStartListening();
          resolve();
        };
        window.speechSynthesis.speak(utterance);
      });
    }

    function limitToThreeSentences(text) {
      const cleaned = (text || "").trim();
      if (!cleaned) return "";
      const parts = cleaned.match(/[^.!?]+[.!?]+|[^.!?]+$/g) || [cleaned];
      return parts.slice(0, 3).join(" ").trim();
    }

    function extractSmartThingsTag(text) {
      const input = String(text || "");
      const regex = /<SMARTTHINGS\s+([^>]+)\/>/i;
      const match = input.match(regex);
      if (!match) {
        return {
          cleanedText: input.trim(),
          action: null,
          target: null,
          brightness: null,
          color: null
        };
      }
      const attrs = match[1] || "";
      const action = (attrs.match(/\baction="([^"]*)"/i)?.[1] || "").toLowerCase();
      const target = attrs.match(/\btarget="([^"]*)"/i)?.[1] || "all";
      const brightness = attrs.match(/\bbrightness="([^"]*)"/i)?.[1] || null;
      const color = attrs.match(/\bcolor="([^"]*)"/i)?.[1] || null;
      const cleanedText = input.replace(regex, "").trim();
      return {
        cleanedText,
        action: ["on", "off"].includes(action) ? action : null,
        target: String(target).trim() || "all",
        brightness: brightness == null ? null : String(brightness).trim(),
        color: color == null ? null : String(color).trim()
      };
    }

    function extractWeatherTag(text) {
      const input = String(text || "");
      const regex = /<WEATHER\s+([^>]+)\/>/i;
      const match = input.match(regex);
      if (!match) {
        return { cleanedText: input.trim(), location: null, type: null, units: null };
      }
      const attrs = match[1] || "";
      const location = attrs.match(/\blocation="([^"]*)"/i)?.[1] || "";
      const type = (attrs.match(/\btype="([^"]*)"/i)?.[1] || "current").toLowerCase();
      const units = (attrs.match(/\bunits="([^"]*)"/i)?.[1] || "imperial").toLowerCase();
      const cleanedText = input.replace(regex, "").trim();
      return {
        cleanedText,
        location: String(location).trim() || DEFAULT_WEATHER_LOCATION,
        type: ["current", "forecast", "air"].includes(type) ? type : "current",
        units: units === "metric" ? "metric" : "imperial"
      };
    }

    async function runSmartThingsAction(action, target, brightness, color) {
      const payload = {};
      if (action) payload.action = action;
      if (target) payload.target = target;
      if (brightness != null && brightness !== "") payload.brightness = brightness;
      if (color) payload.color = color;

      const response = await fetch(smartThingsEndpoint, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(payload)
      });
      const data = await response.json().catch(() => ({}));
      if (!response.ok || !data.ok) {
        throw new Error(data.error || `SmartThings HTTP ${response.status}`);
      }
      const targetText = data.target && data.target !== "all" ? data.target : "lights";
      const parts = [];
      if (action === "on" || action === "off") {
        parts.push(`turned ${action} ${targetText}`);
      } else {
        parts.push(`updated ${targetText}`);
      }
      if (brightness != null && brightness !== "") {
        parts.push(`set brightness to ${brightness} percent`);
      }
      if (color) {
        parts.push(`set color to ${color}`);
      }
      return `I ${parts.join(" and ")}.`;
    }

    async function runWeatherAction(location, type, units) {
      const response = await fetch(weatherEndpoint, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ location, type, units })
      });
      const data = await response.json().catch(() => ({}));
      if (!response.ok || !data.ok) {
        throw new Error(data.error || `Weather HTTP ${response.status}`);
      }

      if (data.type === "air") {
        return `Air quality in ${data.location} is ${data.aqiLabel}.`;
      }

      const unitLabel = data.units === "imperial" ? "F" : "C";
      if (data.type === "forecast") {
        const rain = data.rainChance != null ? ` with ${data.rainChance} percent rain chance` : "";
        return `Forecast for ${data.location}: ${Math.round(data.temp)} degrees ${unitLabel}, ${data.description}${rain}.`;
      }

      return `Current weather in ${data.location}: ${Math.round(data.temp)} degrees ${unitLabel}, feels like ${Math.round(data.feelsLike)} and ${data.description}.`;
    }

    async function askGroq(userText) {
      const body = {
        model: GROQ_MODEL,
        messages: [
          ...conversation,
          { role: "user", content: userText }
        ],
        temperature: 0.8,
        max_tokens: 120
      };

      async function doRequest() {
        return fetch(
          "https://api.groq.com/openai/v1/chat/completions",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "Authorization": `Bearer ${GROQ_API_KEY}`
            },
            body: JSON.stringify(body)
          }
        );
      }

      async function parseGroqError(response) {
        let payload = null;
        let rawText = "";
        try {
          payload = await response.clone().json();
        } catch (_) {
          try {
            rawText = await response.clone().text();
          } catch (_) {
            rawText = "";
          }
        }

        const err = payload?.error || payload || {};
        const status = err.status || err.type || "UNKNOWN_STATUS";
        const code = err.code || response.status;
        const message = err.message || rawText || "Unknown Groq error";
        let detailText = "";

        if (Array.isArray(err.details) && err.details.length) {
          detailText = err.details
            .map((d) => d?.reason || d?.type || JSON.stringify(d))
            .join(", ");
        }

        const composed = `Groq ${response.status} (${status}/${code}): ${message}${detailText ? ` [${detailText}]` : ""}`;
        return composed;
      }

      let res = await doRequest();
      if (res.status === 429) {
        const retryAfter = Number(res.headers.get("retry-after"));
        const waitMs = Number.isFinite(retryAfter) ? retryAfter * 1000 : 2000;
        await new Promise((resolve) => setTimeout(resolve, waitMs));
        res = await doRequest();
      }

      if (res.status === 429) {
        groqCooldownUntil = Date.now() + GROQ_COOLDOWN_MS;
        throw new Error(await parseGroqError(res));
      }

      if (!res.ok) {
        throw new Error(await parseGroqError(res));
      }

      const data = await res.json();
      const text = limitToThreeSentences(data.choices?.[0]?.message?.content?.trim());

      if (!text) {
        throw new Error("No reply text");
      }

      conversation.push({ role: "user", content: userText });
      conversation.push({ role: "assistant", content: text });
      if (conversation.length > 14) {
        conversation = [conversation[0], ...conversation.slice(-13)];
      }
      return text;
    }

    async function handleUserSpeech(userText) {
      if (!userText || assistantBusy) return;
      const now = Date.now();
      const normalized = userText.toLowerCase().trim();
      const wordCount = normalized.split(/\s+/).filter(Boolean).length;

      if (wordCount <= 3) {
        aiStatusEl.textContent = "AI voice: say more than 3 words";
        return;
      }

      if (normalized === lastUserText && now - lastUserTextAt < 4000) {
        aiStatusEl.textContent = "AI voice: duplicate speech ignored";
        return;
      }

      if (now < groqCooldownUntil) {
        const left = Math.ceil((groqCooldownUntil - now) / 1000);
        aiStatusEl.textContent = `AI voice: Groq cooling down (${left}s)`;
        await speak("Give me a moment, I hit my message limit. I will respond again shortly.");
        return;
      }

      if (now - lastGroqCallAt < GROQ_MIN_TURN_GAP_MS) {
        aiStatusEl.textContent = "AI voice: waiting before next AI request";
        return;
      }

      assistantBusy = true;
      setAIMood("thinking");
      playEarcon("thinking");
      lastUserText = normalized;
      lastUserTextAt = now;
      lastGroqCallAt = now;
      aiStatusEl.textContent = `AI voice: heard "${userText}"`;

      try {
        const rawReply = await askGroq(userText);
        const parsedSmart = extractSmartThingsTag(rawReply);
        const parsedWeather = extractWeatherTag(parsedSmart.cleanedText || rawReply);
        let reply = parsedWeather.cleanedText || parsedSmart.cleanedText || rawReply;
        let hasWeatherResponse = false;
        if (parsedSmart.action || parsedSmart.brightness || parsedSmart.color) {
          aiStatusEl.textContent = "AI voice: controlling smart home...";
          try {
            const homeReply = await runSmartThingsAction(
              parsedSmart.action,
              parsedSmart.target || "all",
              parsedSmart.brightness,
              parsedSmart.color
            );
            reply = `${reply} ${homeReply}`.trim();
          } catch (homeErr) {
            reply = `${reply} I could not control the light right now.`.trim();
            aiStatusEl.textContent = `AI voice home error: ${homeErr.message}`;
          }
        }
        if (parsedWeather.location) {
          aiStatusEl.textContent = "AI voice: checking weather...";
          try {
            const weatherReply = await runWeatherAction(
              parsedWeather.location,
              parsedWeather.type || "current",
              parsedWeather.units || "imperial"
            );
            reply = weatherReply.trim();
            hasWeatherResponse = true;
          } catch (weatherErr) {
            reply = "I could not fetch weather right now.";
            aiStatusEl.textContent = `AI weather error: ${weatherErr.message}`;
            hasWeatherResponse = true;
          }
        }

        if (!hasWeatherResponse) {
          reply = reply.trim();
        }
        reply = limitToThreeSentences(reply);
        aiStatusEl.textContent = "AI voice: responding...";
        await speak(reply);
        aiStatusEl.textContent = "AI voice: listening";
        aiMood = "listening";
        updateFaceState();
      } catch (err) {
        aiStatusEl.textContent = `AI voice error: ${err.message}`;
        setAIMood("error", 1200);
        if (String(err.message).toLowerCase().includes("rate limit")) {
          await speak("I am being rate limited right now. Please wait a few seconds and try again.");
        }
      } finally {
        assistantBusy = false;
        if (!assistantSpeaking) {
          setAIMood("idle");
        }
        maybeStartListening();
      }
    }

    function setupSpeechRecognition() {
      if (!SpeechRecognition) {
        aiStatusEl.textContent = "AI voice unavailable: speech recognition not supported";
        return;
      }

      recognition = new SpeechRecognition();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.continuous = false;
      recognition.maxAlternatives = 1;

      recognition.onresult = (event) => {
        const lastResult = event.results?.[event.results.length - 1];
        if (!lastResult || !lastResult.isFinal) return;
        const userText = lastResult?.[0]?.transcript?.trim();
        if (userText) {
          handleUserSpeech(userText);
        }
      };

      recognition.onend = () => {
        recognitionActive = false;
        maybeStartListening();
      };

      recognition.onerror = () => {
        recognitionActive = false;
        maybeStartListening();
      };

      recognition.onnomatch = () => {
        recognitionActive = false;
        maybeStartListening();
      };
    }

    function maybeStartListening() {
      if (!recognition || !voiceEnabled || recognitionActive || assistantBusy || assistantSpeaking || !personVisible) return;
      try {
        recognition.start();
        recognitionActive = true;
        aiStatusEl.textContent = "AI voice: listening";
        setAIMood("listening");
        playEarcon("listen");
      } catch (err) {
        recognitionActive = false;
        setAIMood("error", 900);
        playEarcon("error");
        const msg = String(err?.message || "").toLowerCase();
        if (msg.includes("notallowed") || msg.includes("gesture") || msg.includes("permission")) {
          voiceEnabled = false;
          voiceBtnEl.style.display = "block";
          aiStatusEl.textContent = "AI voice: tap button to enable listening";
        }
      }
    }

    async function greetPersonOnce() {
      if (greetedForCurrentPresence) return;
      greetedForCurrentPresence = true;
      aiStatusEl.textContent = "AI voice: greeting person";
      await speak("Hey there! I can see you. Talk to me and I will chat with you.");
      aiStatusEl.textContent = "AI voice: your turn, I am listening";
      maybeStartListening();
    }

    function decideCommand(centerX, frameWidth) {
      if (centerX == null || !frameWidth) return "STOP";
      const now = Date.now();
      if (now < reacquireUntil) return "FORWARD";

      const normalized = centerX / frameWidth;
      if (smoothedCenterX == null) {
        smoothedCenterX = normalized;
      } else {
        smoothedCenterX = (smoothedCenterX * (1 - CENTER_SMOOTHING)) + (normalized * CENTER_SMOOTHING);
      }

      // Strong hysteresis to prevent rapid LEFT/RIGHT flipping around center.
      if (smoothedCenterX >= LEFT_THRESHOLD && smoothedCenterX <= RIGHT_THRESHOLD) {
        lastSteerCommand = "FORWARD";
        return "FORWARD";
      }

      if (lastSteerCommand === "FORWARD") {
        if (smoothedCenterX < STEER_ENTER_LEFT) {
          lastTurnSetAt = Date.now();
          lastSteerCommand = "LEFT";
          return "LEFT";
        }
        if (smoothedCenterX > STEER_ENTER_RIGHT) {
          lastTurnSetAt = Date.now();
          lastSteerCommand = "RIGHT";
          return "RIGHT";
        }
        return "FORWARD";
      }

      if (lastSteerCommand === "LEFT") {
        if (smoothedCenterX >= LEFT_THRESHOLD) {
          lastSteerCommand = "FORWARD";
          return "FORWARD";
        }
        if (smoothedCenterX > STEER_ENTER_RIGHT && Date.now() - lastTurnSetAt >= TURN_FLIP_GUARD_MS) {
          lastTurnSetAt = Date.now();
          lastSteerCommand = "RIGHT";
          return "RIGHT";
        }
        return "LEFT";
      }

      if (lastSteerCommand === "RIGHT") {
        if (smoothedCenterX <= RIGHT_THRESHOLD) {
          lastSteerCommand = "FORWARD";
          return "FORWARD";
        }
        if (smoothedCenterX < STEER_ENTER_LEFT && Date.now() - lastTurnSetAt >= TURN_FLIP_GUARD_MS) {
          lastTurnSetAt = Date.now();
          lastSteerCommand = "LEFT";
          return "LEFT";
        }
        return "RIGHT";
      }

      lastSteerCommand = "FORWARD";
      return "FORWARD";
    }

    async function startAutoTracking() {
      try {
        await tf.setBackend("webgl");
        await tf.ready();

        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: "user",
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });
        cameraEl.srcObject = stream;
        cameraMiniEl.srcObject = stream;

        await new Promise((resolve) => {
          cameraEl.onloadedmetadata = () => resolve();
        });

        const detector = await poseDetection.createDetector(
          poseDetection.SupportedModels.MoveNet,
          { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING }
        );

        autoStatusEl.textContent = "Auto tracking: running";
        let trackingInFlight = false;
        async function trackStep() {
          if (trackingInFlight) return;
          trackingInFlight = true;
          try {
            const poses = await detector.estimatePoses(cameraMiniEl, { flipHorizontal: false });
            const pose = poses[0];
            drawSkeleton(pose);
            const centerX = pose ? getHumanCenterX(pose) : null;
            const centerY = pose ? getHumanCenterY(pose) : null;
            const rawVisible = centerX != null && centerY != null;
            const now = Date.now();
            if (rawVisible) {
              personLostSince = 0;
              if (!personVisible) {
                reacquireUntil = now + PERSON_REACQUIRE_HOLD_MS;
              }
              personVisible = true;
            } else {
              if (personLostSince === 0) personLostSince = now;
              if (now - personLostSince >= LOST_CONFIRM_MS) {
                personVisible = false;
              }
            }
            let command = "STOP";
            if (personVisible) {
              updateSearchDirectionFromLastSeen(centerX, cameraEl.videoWidth);
              command = decideCommand(centerX, cameraEl.videoWidth);
              lastPersonAt = now;
              if (!greetedForCurrentPresence) {
                playEarcon("found");
              }
              greetPersonOnce();
            } else if (now - lastPersonAt > NO_PERSON_RESET_MS) {
              greetedForCurrentPresence = false;
              command = getSearchCommand();
              autoStatusEl.textContent = `Auto tracking: spin search -> ${command}`;
              if (!assistantBusy && !assistantSpeaking && !recognitionActive) {
                setAIMood("searching");
                aiStatusEl.textContent = "AI voice: searching for person...";
              }
            }

            if (personVisible && command === "STOP") {
              autoStatusEl.textContent = "Auto tracking: person centered fallback -> STOP";
            } else if (personVisible) {
              autoStatusEl.textContent = `Auto tracking: ${command}`;
            }

            sendCommandIfNeeded(command);
          } catch (err) {
            autoStatusEl.textContent = `Auto tracking error: ${err.message}`;
          } finally {
            trackingInFlight = false;
          }
        }

        setInterval(trackStep, 110);
      } catch (error) {
        autoStatusEl.textContent = `Auto tracking unavailable: ${error.message}`;
      }
    }

    document.querySelectorAll("button[data-command]").forEach((button) => {
      button.addEventListener("click", async () => {
        unlockAudio();
        const command = button.dataset.command;
        lastCommand = command;
        lastCommandAt = Date.now();
        await sendCommand(command);
      });
    });

    voiceBtnEl.addEventListener("click", () => {
      unlockAudio();
      voiceEnabled = true;
      voiceBtnEl.style.display = "none";
      maybeStartListening();
    });

    faceModeBtnEl.addEventListener("click", () => {
      unlockAudio();
      enterFaceMode();
    });
    faceBackBtnEl.addEventListener("click", () => {
      unlockAudio();
      exitFaceMode();
    });

    setInterval(() => {
      maybeStartListening();
    }, 1000);

    setupSpeechRecognition();
    updateFaceState();
    startAutoTracking();
  </script>
</body>
</html>
